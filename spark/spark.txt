屏幕共享
  使用ｒｐｃ协议
  在网络中新发送消息时是使用ｓｏｃｋｅｔ协议
－－－－－－－－－－－－－－－－－－－－－－－－－－－
ｓｐａｒｋ
  ｓｐａｒｋ目前在大数据中使用很广泛其收益与其生态圈——实时计算，离线计算，机器学习，图计算
  在使用ｓｐａｒｋ或者ｍａｐｒｅｄｕｃｅ框架时可以不用关注程序底层是如何调用的如何容错的，但是如果不使用这类框架时需要考虑这些问题，因此使用框架可以简化程序员开发程序时的难度并且提高程序员对程序的开发效率
  ＲＤＤ弹性分布式数据集，ＲＤＤ中并不存储真正的数据，在操作ＲＤＤ时会在Ｄｒｉｖｅｒ端转换成ｔａｓｋ，下发到ｅｘｅｃｕｔｏｒ计算分散在多台集群上的数据
  ＲＤＤ是一个代理，你在对代理进行操作，他会生成ｔａｓｋ，帮你计算（优点是不用过多关注细节）
  你操作这个带了，就系那个操作一个本地集合一样，不用担心任务调度，容错等
  ｓｃ．ｔｅｓｔＦｉｌｅ（“”）仅保存元数据信息

ＲＤＤ是一个基本抽象，操作ＲＤＤ就像操作一个本地集合一样，降低了复杂度
ＲＤＤ的算子有两类ｔｒａｎｓｆｏｒｍａｔｉｏｎ（ｌａｚｙ）一类是ａｃｔｉｏｎ（触发任务执行）
创建ＲＤＤ的方式
  １．通过外部的存储系统创建ｒｄｄ
  ２．将ｄｒｉｖｅｒ的Ｓｃａｌａ集合通过并行化的方式编程ＲＤＤ（试验，测试）
  ３．调用一个已经存在的ＲＤＤ
RDD的特点
    1.有很多分区,分区的数量计算资源确定
    //2.抽象集合其中记录元数据的转换关系
    1.一系分区有编号有顺序
    2.每个切片上都会有一个函数会方法作用在上面用于对数据进行处理
    3.RDD和RDD之间存在依赖关系
    4.可选的   k-v类型RDD[(k,v)]会有分区器,默认是hash-Parttioned
    5.可选的 ,如果从hdfs中读取数据,会得到数据的最有位置(在生成任务之前会向namenode请求元数据)通过本地网络来读


集群中的机器在通信时会使用网络(最低局域网)若操作的数据和所需要的软件在同与台机器上则使用本地网络.


排序时智慧改变顺序不会飞里面的数据进行改变
spark中的ｊｉｏｎ仅在有相同的可是才匹配
在数据量大时使用ｒｅｄｕｃｅｂｙｋｅｙ效率会比ｇｒｏｕｐｂｙkｅｙ高很多
ＲＤＤ不存储真正计算机的数据，而是记录了ＲＤＤ的转换关系（调用了什么方法，传入了什么参数）
  在处理数据时为了是数据均匀分配到机器上进行处理新版本的ＲＤＤ在定义时可以传入最小分区数来对数据进行逻辑切分处理

RDD分区的数据取决于哪些因素？
  如果是将driver端Scala集合并行化创建RDD，并且没有制定RDD的分区，RDD的分区就是该APP分配的中的和核数
  如果时从hdfs中毒数据创建RDD，并切设置了最新分区时1，那么RDD的分区及时输入切片的数据，如果不设置最小分区的数量，
  即spark调用textFile时会默认传入2，那么RDD得分区数量就会等于输入切片的数量

---------------------------------------------------------------------------------
RDD 的map方法，真正在executor中执行时，是一条一条的将数据拿来处理

mapPartitionWithIndex
    一次拿出一个分区（分区中并没有数据，而是记录尧都区哪些数据，真正生成task会读取数据），并且可以讲分区的编号取出来
    功能：取分区中对应数据时hi可以将分区中的编号一并取出，这样就可以知道数据时属于哪个分区的或者是哪个分区对应的taskf
计算类问题的优化：
    先进性局部计算再进行全局计算
    aggregate操作时默认值会参与全部运算(包括局部运算和全局运算)

    底层实现combineBykey的方法都具有先局部聚合在全局聚合的功能

    aggregate是一个action类方法仅可对list等集合机型操作不可对key-value数据进行操作
    同为action的方法还有
        collect
        saveAsTextFile
        foreach
        foreachPartition(将大量数据写入另一个地方时使用这个会提高工作效率)
Transformation
    aggregateByKey
    reduceByKey

    map
    mapPartition
    mapPartitionWithIndex
